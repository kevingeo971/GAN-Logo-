{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PLnxRRqVya4R",
    "outputId": "e494f1b6-0f66-4a6a-bb64-808548e73ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-10 05:18:12--  https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5\n",
      "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
      "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13502317373 (13G)\n",
      "Saving to: ‘LLD-logo.hdf5’\n",
      "\n",
      "LLD-logo.hdf5       100%[===================>]  12.57G  19.5MB/s    in 11m 50s \n",
      "\n",
      "2019-11-10 05:30:03 (18.1 MB/s) - ‘LLD-logo.hdf5’ saved [13502317373/13502317373]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q13Xtqbsya4q"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em5rXEQgya5a"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "class HDF5LogoDataLoader(Dataset):\n",
    "    def __init__(self, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.images = self.hdf5_file['data']\n",
    "        self.shapes = self.hdf5_file['shapes']\n",
    "        self.resize_shape = resize_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
    "        img_resized_tensor = TF.to_tensor(img_resized)\n",
    "        # print(img_resized_tensor.max())\n",
    "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
    "        # print(normalize_img.max())\n",
    "        # print(normalize_img.min())\n",
    "        return normalize_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_shape = self.shapes[idx]\n",
    "        # print(self.images[idx].shape)\n",
    "        img_without_padding = self.images[idx][:, :img_shape[1], :img_shape[2]]\n",
    "        return self.transform_image(img_without_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2-C0465ya5y"
   },
   "outputs": [],
   "source": [
    "hdf5_dataset = HDF5LogoDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl6U16pbya6D"
   },
   "outputs": [],
   "source": [
    "def undo_normalize(t, val):\n",
    " return t*val + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXWMtxq1ya7k"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "vjLGrJ6nya76",
    "outputId": "c87b361c-df0e-4a85-c2d7-63e3806345e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf5a875490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.ConvTranspose2d(100, 1024, 4, 1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_2 = nn.ConvTranspose2d(1024, 1024, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv2_1 = nn.ConvTranspose2d(1024, 512, 4, 2, 1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.ConvTranspose2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.ConvTranspose2d(256, 256, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(256, 3, 3)\n",
    "  \n",
    "    def forward(self, latent_vector):\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(latent_vector)))\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
    "\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "gen = Generator()\n",
    "test = torch.randn(10, 100, 1, 1)\n",
    "gen(test).shape\n",
    "\n",
    "output = gen(test)\n",
    "print(output.shape)\n",
    "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z8ymxL6Fya8A",
    "outputId": "05a2f8a1-2f2b-495f-d279-48a379ce6785"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__  (self):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
    "        self.bn1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv1_2 = nn.Conv2d(256, 256, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
    "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "gen = Discriminator()\n",
    "test = torch.randn(10,3,img_size[0],img_size[1])\n",
    "gen(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy-y1suzya8V"
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "generator_model = Generator().cuda()\n",
    "discriminator_model = Discriminator().cuda()\n",
    "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eVErwA_bya8d",
    "outputId": "409b9db9-ea57-4c8f-b017-0f8f0a55575a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1921/1921 [21:17<00:00,  1.50it/s]\n",
      "100%|██████████| 1921/1921 [22:16<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:17<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:19<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:18<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:20<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:19<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:22<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:17<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:17<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:16<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:21<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:15<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:17<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:19<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:16<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:17<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:19<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:21<00:00,  1.43it/s]\n",
      "100%|██████████| 1921/1921 [22:16<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [22:13<00:00,  1.44it/s]\n",
      "100%|██████████| 1921/1921 [17:28<00:00,  1.83it/s]\n",
      "100%|██████████| 1921/1921 [16:34<00:00,  1.93it/s]\n",
      "100%|██████████| 1921/1921 [16:39<00:00,  1.92it/s]\n",
      "100%|██████████| 1921/1921 [16:27<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7h 44min 11s, sys: 1h 11min 10s, total: 8h 55min 22s\n",
      "Wall time: 8h 54min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 25\n",
    "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "#x = next(iter(hdf5_dataloader))\n",
    "\n",
    "disp_img = 100\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(\"Epoch : \", epoch)\n",
    "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
    "        \n",
    "        for i in range(2):\n",
    "        #   dataloader_iter = iter(hdf5_dataloader)\n",
    "            current_batch_size = BATCH_SIZE\n",
    "            #real_images = x.cuda()\n",
    "            #     print(real_images.shape)\n",
    "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
    "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
    "            # Generator Training\n",
    "            latent_vals = torch.randn((current_batch_size, LATENT_SIZE, 1, 1)).cuda()\n",
    "            # print(latent_vals.shape)\n",
    "            generated_fakes = generator_model(latent_vals)\n",
    "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
    "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
    "            generator_loss = -torch.mean( discriminator_results_for_fakes )\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "                    \n",
    "            plt.savefig(\"Gen_2X/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "        \n",
    "        # Discriminator Training\n",
    "        #for i in range(2):\n",
    "          #x = next(dataloader_iter)  \n",
    "        current_batch_size = x.shape[0]\n",
    "        real_images = x.cuda()\n",
    "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
    "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
    "          # We detach the generated_fakes because we are only training discriminator in this \n",
    "          # phase. detach() prevents the gradients from being propagated\n",
    "          #import pdb;pdb.set_trace()\n",
    "          \n",
    "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
    "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
    "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
    "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
    "          #total_loss = fake_loss + real_loss\n",
    "        total_loss = - (real_loss - fake_loss) \n",
    "        optimizer_D.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_D.step()\n",
    "          \n",
    "        for p in discriminator_model.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-TnnYRrya8h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP20neKDya8l"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 100 1024, but got 2-dimensional input of size [1, 100] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f1df892ff8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_gen_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-73529e94cadd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, latent_vector)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    785\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    786\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 100 1024, but got 2-dimensional input of size [1, 100] instead"
     ]
    }
   ],
   "source": [
    "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
    "\n",
    "test_gen_image = generator_model(test_latent)\n",
    "print(test_gen_image.shape)\n",
    "\n",
    "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "numpy_img = undo_normalize(numpy_img, 127.5)\n",
    "print(numpy_img.max())\n",
    "plt.imshow(numpy_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqWkh0bpya8q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy_of_Computer_Vision_Project_Gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
