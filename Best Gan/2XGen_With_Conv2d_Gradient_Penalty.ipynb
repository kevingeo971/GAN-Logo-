{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of 2XGen_With_Conv2d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLnxRRqVya4R",
        "outputId": "bb47e1ea-1108-47c8-ee08-ebaa36bbc7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-21 00:26:23--  https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13502317373 (13G)\n",
            "Saving to: ‘LLD-logo.hdf5’\n",
            "\n",
            "LLD-logo.hdf5       100%[===================>]  12.57G  18.8MB/s    in 11m 39s \n",
            "\n",
            "2019-11-21 00:38:03 (18.4 MB/s) - ‘LLD-logo.hdf5’ saved [13502317373/13502317373]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q13Xtqbsya4q",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm_notebook, trange, tqdm\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.optim as optim\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Em5rXEQgya5a",
        "colab": {}
      },
      "source": [
        "img_size = (32, 32)\n",
        "class HDF5LogoDataLoader(Dataset):\n",
        "    def __init__(self, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
        "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
        "        self.images = self.hdf5_file['data']\n",
        "        self.shapes = self.hdf5_file['shapes']\n",
        "        self.resize_shape = resize_shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def transform_image(self, image):\n",
        "        image = image.transpose(1, 2, 0)\n",
        "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
        "        img_resized_tensor = TF.to_tensor(img_resized)\n",
        "        # print(img_resized_tensor.max())\n",
        "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
        "        # print(normalize_img.max())\n",
        "        # print(normalize_img.min())\n",
        "        return normalize_img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_shape = self.shapes[idx]\n",
        "        # print(self.images[idx].shape)\n",
        "        img_without_padding = self.images[idx][:, :img_shape[1], :img_shape[2]]\n",
        "        return self.transform_image(img_without_padding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d2-C0465ya5y",
        "colab": {}
      },
      "source": [
        "hdf5_dataset = HDF5LogoDataLoader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tl6U16pbya6D",
        "colab": {}
      },
      "source": [
        "def undo_normalize(t, val):\n",
        " return t*val + val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CXWMtxq1ya7k",
        "colab": {}
      },
      "source": [
        "img_size = (32, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjLGrJ6nya76",
        "outputId": "e42c7d2b-461f-40b2-fe16-afdc286b9bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.conv1_1 = nn.ConvTranspose2d(100, 1024, 4, 1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
        "        self.conv1_2 = nn.Conv2d(1024, 1024, 3,padding=2)\n",
        "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
        "        self.conv1_3 = nn.Conv2d(1024, 1024, 3,padding=1)\n",
        "        self.bn1_3 = nn.BatchNorm2d(1024)\n",
        "        \n",
        "        self.conv2_1 = nn.ConvTranspose2d(1024, 512, 4, 2, 1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(512)\n",
        "        self.conv2_2 = nn.Conv2d(512, 512, 3, padding=2)\n",
        "        self.bn2_2 = nn.BatchNorm2d(512)\n",
        "        self.conv2_3 = nn.Conv2d(512, 512, 3,padding=1)\n",
        "        self.bn2_3 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv3_1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(256)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=2)\n",
        "        self.bn3_2 = nn.BatchNorm2d(256)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn3_3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.conv4 = nn.ConvTranspose2d(256, 3, 3)\n",
        "  \n",
        "    def forward(self, latent_vector):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(latent_vector)))\n",
        "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
        "        x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
        "        \n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
        "        x = F.relu(self.bn2_3(self.conv2_3(x)))\n",
        "        \n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
        "        x = F.relu(self.bn3_3(self.conv3_3(x)))\n",
        "\n",
        "        x = torch.tanh(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "gen = Generator()\n",
        "test = torch.randn(10, 100, 1, 1)\n",
        "#gen(test).shape\n",
        "\n",
        "output = gen(test)\n",
        "#print()\n",
        "print(output.shape)\n",
        "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f16e3b124a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWLAbhk+wYDcMn2DBbhg+wYLdMHzC/wKgLEBe3jn/IQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8ymxL6Fya8A",
        "outputId": "53b5a627-a543-4d1b-af47-af2d65716370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__  (self):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
        "        self.bn1_1 = nn.BatchNorm2d(256)\n",
        "        self.conv1_2 = nn.Conv2d(256, 256, 3 )\n",
        "        self.bn1_2 = nn.BatchNorm2d(256)\n",
        "        self.conv1_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
        "        self.bn2_1 = nn.BatchNorm2d(512)\n",
        "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
        "        self.bn2_2 = nn.BatchNorm2d(512)\n",
        "        self.conv2_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.bn2_3 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
        "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
        "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
        "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
        "        self.conv3_3 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
        "        self.bn3_3 = nn.BatchNorm2d(1024)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
        "        \n",
        "        \n",
        "\n",
        "    def forward(self, img):\n",
        "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn1_3(self.conv1_3(x)),negative_slope=0.2)\n",
        "\n",
        "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn2_3(self.conv2_3(x)),negative_slope=0.2)\n",
        "\n",
        "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.bn3_3(self.conv3_3(x)),negative_slope=0.2)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        return x.view(-1, 1)\n",
        "\n",
        "gen = Discriminator()\n",
        "test = torch.randn(10,3,img_size[0],img_size[1])\n",
        "gen(test).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWqBBei4Wig_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.cuda.FloatTensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = torch.cuda.FloatTensor(real_samples.shape[0], 1).fill_(1.0).cuda().requires_grad_(False)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wy-y1suzya8V",
        "colab": {}
      },
      "source": [
        "LATENT_SIZE = 100\n",
        "BATCH_SIZE = 32\n",
        "generator_model = Generator().cuda()\n",
        "discriminator_model = Discriminator().cuda()\n",
        "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "bce_loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eVErwA_bya8d",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "NUM_EPOCHS = 1\n",
        "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
        "#x = next(iter(hdf5_dataloader))\n",
        "\n",
        "disp_img = 100\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # print(\"Epoch : \", epoch)\n",
        "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
        "        \n",
        "        for i in range(2):\n",
        "        #   dataloader_iter = iter(hdf5_dataloader)\n",
        "            current_batch_size = BATCH_SIZE\n",
        "            #real_images = x.cuda()\n",
        "            #     print(real_images.shape)\n",
        "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
        "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
        "            # Generator Training\n",
        "            latent_vals = torch.randn((current_batch_size, LATENT_SIZE, 1, 1)).cuda()\n",
        "            # print(latent_vals.shape)\n",
        "            generated_fakes = generator_model(latent_vals)\n",
        "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
        "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
        "            generator_loss = -torch.mean(discriminator_results_for_fakes)\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            generator_loss.backward()\n",
        "            optimizer_G.step()\n",
        "        \n",
        "        if iterate%disp_img==0:\n",
        "            c = 0\n",
        "            fig, ax = plt.subplots(3,3)\n",
        "            for pi in range(3):\n",
        "                for pj in range(3):\n",
        "                    ax[pi][pj].axis('off')\n",
        "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
        "                    c+=1\n",
        "                    \n",
        "            plt.savefig(\"Gen_2X/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
        "            plt.close()\n",
        "        \n",
        "        # Discriminator Training\n",
        "        #for i in range(2):\n",
        "          #x = next(dataloader_iter)  \n",
        "        current_batch_size = x.shape[0]\n",
        "        real_images = x.cuda()\n",
        "\n",
        "        \n",
        "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
        "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
        "        \n",
        "          # We detach the generated_fakes because we are only training discriminator in this \n",
        "          # phase. detach() prevents the gradients from being propagated\n",
        "          #import pdb;pdb.set_trace()\n",
        "          \n",
        "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
        "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
        "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
        "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
        "        gradient_penalty = compute_gradient_penalty(discriminator_model, real_images, generated_fakes.detach())\n",
        "          #total_loss = fake_loss + real_loss\n",
        "        total_loss = - (real_loss - fake_loss) + 10 * gradient_penalty\n",
        "        optimizer_D.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer_D.step()\n",
        "          \n",
        "        for p in discriminator_model.parameters():\n",
        "            p.data.clamp_(-0.01, 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB_Ruqzfcn4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%debug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7-TnnYRrya8h",
        "colab": {}
      },
      "source": [
        "himport matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bP20neKDya8l",
        "outputId": "4b34a29b-890a-46ce-8ef7-ceb4127c6fd7",
        "colab": {}
      },
      "source": [
        "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
        "\n",
        "test_gen_image = generator_model(test_latent)\n",
        "print(test_gen_image.shape)\n",
        "\n",
        "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
        "\n",
        "numpy_img = undo_normalize(numpy_img, 127.5)\n",
        "print(numpy_img.max())\n",
        "plt.imshow(numpy_img.astype(np.uint8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected 4-dimensional input for 4-dimensional weight 100 1024, but got 2-dimensional input of size [1, 100] instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f1df892ff8c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_gen_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gen_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-73529e94cadd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, latent_vector)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    785\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    786\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 100 1024, but got 2-dimensional input of size [1, 100] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iqWkh0bpya8q",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}