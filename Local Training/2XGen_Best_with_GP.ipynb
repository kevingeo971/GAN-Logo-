{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PLnxRRqVya4R",
    "outputId": "e494f1b6-0f66-4a6a-bb64-808548e73ff2"
   },
   "outputs": [],
   "source": [
    "#!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q13Xtqbsya4q"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em5rXEQgya5a"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "class HDF5LogoDataLoader(Dataset):\n",
    "    def __init__(self, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.images = self.hdf5_file['data']\n",
    "        print(self.images.shape)\n",
    "        self.shapes = self.hdf5_file['shapes']\n",
    "        print( self.hdf5_file['/labels/'])\n",
    "        self.resize_shape = resize_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
    "        img_resized_tensor = TF.to_tensor(img_resized)\n",
    "        # print(img_resized_tensor.max())\n",
    "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
    "        # print(normalize_img.max())\n",
    "        # print(normalize_img.min())\n",
    "        return normalize_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_shape = self.shapes[idx]\n",
    "        # print(self.images[idx].shape)\n",
    "        img_without_padding = self.images[idx][:, :img_shape[1], :img_shape[2]]\n",
    "        return self.transform_image(img_without_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2-C0465ya5y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122920, 3, 400, 400)\n",
      "<HDF5 group \"/labels\" (2 members)>\n"
     ]
    }
   ],
   "source": [
    "hdf5_dataset = HDF5LogoDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl6U16pbya6D"
   },
   "outputs": [],
   "source": [
    "def undo_normalize(t, val):\n",
    " return t*val + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXWMtxq1ya7k"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "vjLGrJ6nya76",
    "outputId": "c87b361c-df0e-4a85-c2d7-63e3806345e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28e8b8c0eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.ConvTranspose2d(100, 1024, 4, 1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_2 = nn.ConvTranspose2d(1024, 1024, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv2_1 = nn.ConvTranspose2d(1024, 512, 4, 2, 1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.ConvTranspose2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.ConvTranspose2d(256, 256, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(256, 3, 3)\n",
    "  \n",
    "    def forward(self, latent_vector):\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(latent_vector)))\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
    "\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "gen = Generator()\n",
    "test = torch.randn(10, 100, 1, 1)\n",
    "gen(test).shape\n",
    "\n",
    "output = gen(test)\n",
    "print(output.shape)\n",
    "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z8ymxL6Fya8A",
    "outputId": "05a2f8a1-2f2b-495f-d279-48a379ce6785"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__  (self):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
    "        self.bn1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv1_2 = nn.Conv2d(256, 256, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
    "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "gen = Discriminator()\n",
    "test = torch.randn(10,3,img_size[0],img_size[1])\n",
    "gen(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.cuda.FloatTensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = torch.cuda.FloatTensor(real_samples.shape[0], 1).fill_(1.0).cuda().requires_grad_(False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy-y1suzya8V"
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "generator_model = Generator().cuda()\n",
    "discriminator_model = Discriminator().cuda()\n",
    "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eVErwA_bya8d",
    "outputId": "409b9db9-ea57-4c8f-b017-0f8f0a55575a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [55:16<00:00,  1.73s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [55:09<00:00,  1.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [54:59<00:00,  1.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [54:57<00:00,  1.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [55:01<00:00,  1.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [54:59<00:00,  1.72s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [55:02<00:00,  1.73s/it]\n",
      " 98%|████████████████████████████████████████████████████████████████████████████▌ | 1885/1920 [53:58<01:00,  1.72s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 25\n",
    "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "#x = next(iter(hdf5_dataloader))\n",
    "\n",
    "disp_img = 500\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(\"Epoch : \", epoch)\n",
    "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
    "        \n",
    "        for i in range(2):\n",
    "        #   dataloader_iter = iter(hdf5_dataloader)\n",
    "            current_batch_size = BATCH_SIZE\n",
    "            #real_images = x.cuda()\n",
    "            #     print(real_images.shape)\n",
    "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
    "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
    "            # Generator Training\n",
    "            latent_vals = torch.randn((current_batch_size, LATENT_SIZE, 1, 1)).cuda()\n",
    "            # print(latent_vals.shape)\n",
    "            generated_fakes = generator_model(latent_vals)\n",
    "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
    "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
    "            generator_loss = -torch.mean( discriminator_results_for_fakes )\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "                    \n",
    "            plt.savefig(\"Gen_2X_GP/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "            torch.save(generator_model.state_dict(), \"generator_shallow_GP.pth \")\n",
    "            torch.save(discriminator_model.state_dict(), \"discriminator_shallow_GP.pth\")\n",
    "        \n",
    "        # Discriminator Training\n",
    "        #for i in range(2):\n",
    "          #x = next(dataloader_iter)  \n",
    "        current_batch_size = x.shape[0]\n",
    "        real_images = x.cuda()\n",
    "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
    "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
    "          # We detach the generated_fakes because we are only training discriminator in this \n",
    "          # phase. detach() prevents the gradients from being propagated\n",
    "          #import pdb;pdb.set_trace()\n",
    "          \n",
    "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
    "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
    "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
    "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
    "          #total_loss = fake_loss + real_loss\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator_model, real_images, generated_fakes.detach())\n",
    "        total_loss = - (real_loss - fake_loss) + 10 * gradient_penalty\n",
    "        optimizer_D.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_D.step()\n",
    "          \n",
    "        for p in discriminator_model.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-TnnYRrya8h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP20neKDya8l"
   },
   "outputs": [],
   "source": [
    "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
    "\n",
    "test_gen_image = generator_model(test_latent)\n",
    "print(test_gen_image.shape)\n",
    "\n",
    "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "numpy_img = undo_normalize(numpy_img, 127.5)\n",
    "print(numpy_img.max())\n",
    "plt.imshow(numpy_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqWkh0bpya8q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy_of_Computer_Vision_Project_Gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
