{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "PLnxRRqVya4R",
    "outputId": "bb47e1ea-1108-47c8-ee08-ebaa36bbc7e8"
   },
   "outputs": [],
   "source": [
    "#!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q13Xtqbsya4q"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em5rXEQgya5a"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "class HDF5LogoDataLoader(Dataset):\n",
    "    def __init__(self, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.images = self.hdf5_file['data']\n",
    "        self.shapes = self.hdf5_file['shapes']\n",
    "        self.resize_shape = resize_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
    "        img_resized_tensor = TF.to_tensor(img_resized)\n",
    "        # print(img_resized_tensor.max())\n",
    "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
    "        # print(normalize_img.max())\n",
    "        # print(normalize_img.min())\n",
    "        return normalize_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_shape = self.shapes[idx]\n",
    "        # print(self.images[idx].shape)\n",
    "        img_without_padding = self.images[idx][:, :img_shape[1], :img_shape[2]]\n",
    "        return self.transform_image(img_without_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2-C0465ya5y"
   },
   "outputs": [],
   "source": [
    "hdf5_dataset = HDF5LogoDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl6U16pbya6D"
   },
   "outputs": [],
   "source": [
    "def undo_normalize(t, val):\n",
    " return t*val + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXWMtxq1ya7k"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "vjLGrJ6nya76",
    "outputId": "e42c7d2b-461f-40b2-fe16-afdc286b9bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa00040588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.ConvTranspose2d(100, 1024, 4, 1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_2 = nn.Conv2d(1024, 1024, 3,padding=2)\n",
    "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_3 = nn.Conv2d(1024, 1024, 3,padding=1)\n",
    "        self.bn1_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv2_1 = nn.ConvTranspose2d(1024, 512, 4, 2, 1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3, padding=2)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "        self.conv2_3 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "        self.bn2_3 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=2)\n",
    "        self.bn3_2 = nn.BatchNorm2d(256)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn3_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(256, 3, 3)\n",
    "  \n",
    "    def forward(self, latent_vector):\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(latent_vector)))\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "        x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
    "        x = F.relu(self.bn2_3(self.conv2_3(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
    "        x = F.relu(self.bn3_3(self.conv3_3(x)))\n",
    "\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "gen = Generator()\n",
    "test = torch.randn(10, 100, 1, 1)\n",
    "#gen(test).shape\n",
    "\n",
    "output = gen(test)\n",
    "#print()\n",
    "print(output.shape)\n",
    "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z8ymxL6Fya8A",
    "outputId": "53b5a627-a543-4d1b-af47-af2d65716370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__  (self):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
    "        self.bn1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv1_2 = nn.Conv2d(256, 256, 3 )\n",
    "        self.bn1_2 = nn.BatchNorm2d(256)\n",
    "        self.conv1_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn1_3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "        self.conv2_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2_3 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
    "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_3 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.bn3_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_3(self.conv1_3(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_3(self.conv2_3(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_3(self.conv3_3(x)),negative_slope=0.2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "gen = Discriminator()\n",
    "test = torch.randn(10,3,img_size[0],img_size[1])\n",
    "gen(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWqBBei4Wig_"
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.cuda.FloatTensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = torch.cuda.FloatTensor(real_samples.shape[0], 1).fill_(1.0).cuda().requires_grad_(False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy-y1suzya8V"
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "BATCH_SIZE = 56\n",
    "generator_model = Generator().cuda()\n",
    "discriminator_model = Discriminator().cuda()\n",
    "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVErwA_bya8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2195/2195 [1:11:30<00:00,  1.96s/it]\n",
      " 12%|█████████▍                                                                   | 268/2195 [08:46<1:03:00,  1.96s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 2\n",
    "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "#x = next(iter(hdf5_dataloader))\n",
    "\n",
    "disp_img = 500\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(\"Epoch : \", epoch)\n",
    "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
    "        \n",
    "        for i in range(2):\n",
    "        #   dataloader_iter = iter(hdf5_dataloader)\n",
    "            current_batch_size = BATCH_SIZE\n",
    "            #real_images = x.cuda()\n",
    "            #     print(real_images.shape)\n",
    "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
    "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
    "            # Generator Training\n",
    "            latent_vals = torch.randn((current_batch_size, LATENT_SIZE, 1, 1)).cuda()\n",
    "            # print(latent_vals.shape)\n",
    "            generated_fakes = generator_model(latent_vals)\n",
    "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
    "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
    "            generator_loss = -torch.mean(discriminator_results_for_fakes)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "                    \n",
    "            plt.savefig(\"Gen_2X_Conv2d/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "            torch.save(generator_model.state_dict(), \"generator_conv2d.pth \")\n",
    "            torch.save(discriminator_model.state_dict(), \"discriminator_conv2d.pth\")\n",
    "            \n",
    "        \n",
    "        # Discriminator Training\n",
    "        #for i in range(2):\n",
    "          #x = next(dataloader_iter)  \n",
    "        current_batch_size = x.shape[0]\n",
    "        real_images = x.cuda()\n",
    "\n",
    "        \n",
    "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
    "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
    "        \n",
    "          # We detach the generated_fakes because we are only training discriminator in this \n",
    "          # phase. detach() prevents the gradients from being propagated\n",
    "          #import pdb;pdb.set_trace()\n",
    "          \n",
    "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
    "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
    "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
    "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator_model, real_images, generated_fakes.detach())\n",
    "          #total_loss = fake_loss + real_loss\n",
    "        total_loss = - (real_loss - fake_loss) + 10 * gradient_penalty\n",
    "        optimizer_D.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        for p in discriminator_model.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oB_Ruqzfcn4p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-TnnYRrya8h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP20neKDya8l",
    "outputId": "4b34a29b-890a-46ce-8ef7-ceb4127c6fd7"
   },
   "outputs": [],
   "source": [
    "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
    "\n",
    "test_gen_image = generator_model(test_latent)\n",
    "print(test_gen_image.shape)\n",
    "\n",
    "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "numpy_img = undo_normalize(numpy_img, 127.5)\n",
    "print(numpy_img.max())\n",
    "plt.imshow(numpy_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqWkh0bpya8q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 2XGen_With_Conv2d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
