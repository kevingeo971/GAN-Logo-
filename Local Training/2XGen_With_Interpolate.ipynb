{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "PLnxRRqVya4R",
    "outputId": "bb47e1ea-1108-47c8-ee08-ebaa36bbc7e8"
   },
   "outputs": [],
   "source": [
    "#!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q13Xtqbsya4q"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em5rXEQgya5a"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "class HDF5LogoDataLoader(Dataset):\n",
    "    def __init__(self, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.images = self.hdf5_file['data']\n",
    "        self.shapes = self.hdf5_file['shapes']\n",
    "        self.resize_shape = resize_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
    "        img_resized_tensor = TF.to_tensor(img_resized)\n",
    "        # print(img_resized_tensor.max())\n",
    "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
    "        # print(normalize_img.max())\n",
    "        # print(normalize_img.min())\n",
    "        return normalize_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_shape = self.shapes[idx]\n",
    "        # print(self.images[idx].shape)\n",
    "        img_without_padding = self.images[idx][:, :img_shape[1], :img_shape[2]]\n",
    "        return self.transform_image(img_without_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2-C0465ya5y"
   },
   "outputs": [],
   "source": [
    "hdf5_dataset = HDF5LogoDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl6U16pbya6D"
   },
   "outputs": [],
   "source": [
    "def undo_normalize(t, val):\n",
    " return t*val + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXWMtxq1ya7k"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2KBp4f7ceq_R",
    "outputId": "c3ccfd56-eba2-42f6-9a86-a74e2e8c59de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 16, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.interpolate(torch.randn(10, 3, 10, 10), scale_factor=1.6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "vjLGrJ6nya76",
    "outputId": "db356560-6554-4838-d26d-af8d79c21dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b743090b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(1, 1024, 3, padding=1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_2 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
    "#         self.conv1_3 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "#         self.bn1_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(1024, 512, 3, padding=1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "#         self.conv2_3 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "#         self.bn2_3 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn3_2 = nn.BatchNorm2d(256)\n",
    "#         self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "#         self.bn3_3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 3, 3, padding=1)\n",
    "  \n",
    "    def forward(self, latent_vector):\n",
    "\n",
    "        x = F.interpolate(latent_vector, size=(16, 16))\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "#         x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
    "        \n",
    "        x = F.interpolate(x, size=(24, 24))\n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
    "#         x = F.relu(self.bn2_3(self.conv2_3(x)))\n",
    "        \n",
    "        x = F.interpolate(x, size=(32, 32))\n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
    "#         x = F.relu(self.bn3_3(self.conv3_3(x)))\n",
    "\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "gen = Generator()\n",
    "test = torch.randn(10, 1, 10, 10)\n",
    "#gen(test).shape\n",
    "\n",
    "output = gen(test)\n",
    "#print()\n",
    "print(output.shape)\n",
    "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z8ymxL6Fya8A",
    "outputId": "7980df69-0008-4bd9-df65-dd6a476c02dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__  (self):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
    "        self.bn1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv1_2 = nn.Conv2d(256, 256, 3 )\n",
    "        self.bn1_2 = nn.BatchNorm2d(256)\n",
    "#         self.conv1_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "#         self.bn1_3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "#         self.conv2_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "#         self.bn2_3 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
    "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
    "#         self.conv3_3 = nn.Conv2d(1024, 1024, 3, padding=1)\n",
    "#         self.bn3_3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
    "#         x = F.leaky_relu(self.bn1_3(self.conv1_3(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
    "#         x = F.leaky_relu(self.bn2_3(self.conv2_3(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
    "#         x = F.leaky_relu(self.bn3_3(self.conv3_3(x)),negative_slope=0.2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "gen = Discriminator()\n",
    "test = torch.randn(10,3,img_size[0],img_size[1])\n",
    "gen(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWqBBei4Wig_"
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = torch.cuda.FloatTensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = torch.cuda.FloatTensor(real_samples.shape[0], 1).fill_(1.0).cuda().requires_grad_(False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy-y1suzya8V"
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "generator_model = Generator().cuda()\n",
    "discriminator_model = Discriminator().cuda()\n",
    "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eVErwA_bya8d",
    "outputId": "55f36c80-d39a-446b-e2e6-f98748e63523"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:55<00:00,  1.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:51<00:00,  1.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:50<00:00,  1.48s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:49<00:00,  1.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:57<00:00,  1.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:11<00:00,  1.50s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:42<00:00,  1.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:53<00:00,  1.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [46:58<00:00,  1.48s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:01<00:00,  1.48s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:04<00:00,  1.49s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:02<00:00,  1.47s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1920/1920 [47:04<00:00,  1.47s/it]\n",
      " 21%|████████████████▍                                                              | 399/1920 [09:43<37:17,  1.47s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 35\n",
    "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "#x = next(iter(hdf5_dataloader))\n",
    "\n",
    "disp_img = 500\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(\"Epoch : \", epoch)\n",
    "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
    "#         print(x.shape)\n",
    "        for i in range(2):\n",
    "        #   dataloader_iter = iter(hdf5_dataloader)\n",
    "            current_batch_size = BATCH_SIZE\n",
    "            #real_images = x.cuda()\n",
    "            #     print(real_images.shape)\n",
    "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
    "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
    "            # Generator Training\n",
    "            latent_vals = torch.randn((current_batch_size, 1, 10, 10)).cuda()\n",
    "            # print(latent_vals.shape)\n",
    "            generated_fakes = generator_model(latent_vals)\n",
    "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
    "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
    "            generator_loss = -torch.mean(discriminator_results_for_fakes)\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "                    \n",
    "            plt.savefig(\"Gen_2X_Interpolate/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "            torch.save(generator_model.state_dict(), \"generator_interpolate.pth \")\n",
    "            torch.save(discriminator_model.state_dict(), \"discriminator_interpolate.pth\")\n",
    "            \n",
    "        \n",
    "        # Discriminator Training\n",
    "        #for i in range(2):\n",
    "          #x = next(dataloader_iter)  \n",
    "        current_batch_size = x.shape[0]\n",
    "        real_images = x.cuda()\n",
    "\n",
    "        \n",
    "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
    "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
    "        \n",
    "          # We detach the generated_fakes because we are only training discriminator in this \n",
    "          # phase. detach() prevents the gradients from being propagated\n",
    "          #import pdb;pdb.set_trace()\n",
    "          \n",
    "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
    "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
    "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
    "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
    "        #gradient_penalty = compute_gradient_penalty(discriminator_model, real_images, generated_fakes.detach())\n",
    "          #total_loss = fake_loss + real_loss\n",
    "        total_loss = - (real_loss - fake_loss)# + 10 * gradient_penalty\n",
    "        optimizer_D.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_D.step()\n",
    "          \n",
    "        for p in discriminator_model.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-TnnYRrya8h"
   },
   "outputs": [],
   "source": [
    "himport matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP20neKDya8l",
    "outputId": "4b34a29b-890a-46ce-8ef7-ceb4127c6fd7"
   },
   "outputs": [],
   "source": [
    "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
    "\n",
    "test_gen_image = generator_model(test_latent)\n",
    "print(test_gen_image.shape)\n",
    "\n",
    "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "numpy_img = undo_normalize(numpy_img, 127.5)\n",
    "print(numpy_img.max())\n",
    "plt.imshow(numpy_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqWkh0bpya8q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 2XGen_With_Conv2d.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
