{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PLnxRRqVya4R",
    "outputId": "e494f1b6-0f66-4a6a-bb64-808548e73ff2"
   },
   "outputs": [],
   "source": [
    "#V100\n",
    "#!wget https://data.vision.ee.ethz.ch/sagea/lld/data/LLD-logo.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q13Xtqbsya4q"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path='LLD-logo.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 5736)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(hdf5_file['labels']['resnet']['rc_64'][:])\n",
    "max_ind = 0\n",
    "max_i = 0\n",
    "for i in range(32):\n",
    "    ind = np.argwhere( x == i )\n",
    "    if ind.shape[0]>max_ind:\n",
    "        max_ind = ind.shape[0]\n",
    "        max_i = i\n",
    "        \n",
    "max_i, max_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(hdf5_file['labels']['resnet']['rc_64'][:])\n",
    "ind = np.argwhere(x == 20).squeeze().tolist()\n",
    "len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Em5rXEQgya5a"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "class HDF5LogoDataLoader(Dataset):\n",
    "    def __init__(self, cluster_indices, hdf5_path='LLD-logo.hdf5', resize_shape=img_size):\n",
    "        self.hdf5_file = h5py.File(hdf5_path, 'r')\n",
    "        self.images = self.hdf5_file['data']\n",
    "        self.shapes = self.hdf5_file['shapes']\n",
    "        self.resize_shape = resize_shape\n",
    "        self.cluster_indices = cluster_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cluster_indices)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        image = image.transpose(1, 2, 0)\n",
    "        img_resized = cv2.resize(image, dsize=self.resize_shape)\n",
    "        img_resized_tensor = TF.to_tensor(img_resized)\n",
    "        # print(img_resized_tensor.max())\n",
    "        normalize_img = TF.normalize(img_resized_tensor, mean=[127.5,127.5,127.5], std=[127.5,127.5,127.5])\n",
    "        # print(normalize_img.max())\n",
    "        # print(normalize_img.min())\n",
    "        return normalize_img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_index = self.cluster_indices[idx]\n",
    "        img_shape = self.shapes[actual_index]\n",
    "        # print(self.images[idx].shape)\n",
    "        img_without_padding = self.images[actual_index][:, :img_shape[1], :img_shape[2]]\n",
    "        return self.transform_image(img_without_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2-C0465ya5y"
   },
   "outputs": [],
   "source": [
    "hdf5_dataset = HDF5LogoDataLoader(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl6U16pbya6D"
   },
   "outputs": [],
   "source": [
    "def undo_normalize(t, val):\n",
    " return t*val + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXWMtxq1ya7k"
   },
   "outputs": [],
   "source": [
    "img_size = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "vjLGrJ6nya76",
    "outputId": "c87b361c-df0e-4a85-c2d7-63e3806345e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f528402d990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.ConvTranspose2d(100, 1024, 4, 1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv1_2 = nn.ConvTranspose2d(1024, 1024, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv2_1 = nn.ConvTranspose2d(1024, 512, 4, 2, 1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.ConvTranspose2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv3_1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.ConvTranspose2d(256, 256, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(256, 3, 3)\n",
    "  \n",
    "    def forward(self, latent_vector):\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(latent_vector)))\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
    "\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "gen = Generator()\n",
    "test = torch.randn(10, 100, 1, 1)\n",
    "gen(test).shape\n",
    "\n",
    "output = gen(test)\n",
    "print(output.shape)\n",
    "plt.imshow(undo_normalize(output[0], 127.5).detach().numpy().transpose(1, 2, 0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z8ymxL6Fya8A",
    "outputId": "05a2f8a1-2f2b-495f-d279-48a379ce6785"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__  (self):\n",
    "\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 256, 4, 2, 2)\n",
    "        self.bn1_1 = nn.BatchNorm2d(256)\n",
    "        self.conv1_2 = nn.Conv2d(256, 256, 3)\n",
    "        self.bn1_2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(256, 512, 4, 2, 2)\n",
    "        self.bn2_1 = nn.BatchNorm2d(512)\n",
    "        self.conv2_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn2_2 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(512, 1024, 4, 2, 2)\n",
    "        self.bn3_1 = nn.BatchNorm2d(1024)\n",
    "        self.conv3_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.bn3_2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(1024, 1, 2)\n",
    "        \n",
    "        #self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = F.leaky_relu(self.bn1_1(self.conv1_1(img)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn1_2(self.conv1_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn2_1(self.conv2_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn2_2(self.conv2_2(x)),negative_slope=0.2)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3_1(self.conv3_1(x)),negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.bn3_2(self.conv3_2(x)),negative_slope=0.2)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        return x.view(-1, 1)\n",
    "\n",
    "gen = Discriminator()\n",
    "test = torch.randn(10,3,img_size[0],img_size[1])\n",
    "gen(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy-y1suzya8V"
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "generator_model = Generator().cuda()\n",
    "discriminator_model = Discriminator().cuda()\n",
    "hdf5_dataloader = DataLoader(hdf5_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eVErwA_bya8d",
    "outputId": "409b9db9-ea57-4c8f-b017-0f8f0a55575a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.52it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.53it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.54it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.54it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.52it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.50it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.39it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.34it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.54it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.22it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.53it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.07it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.33it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.08it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.54it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.53it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.54it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.55it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:09<00:00,  2.85it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.51it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.50it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:09<00:00,  2.66it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.50it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.31it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.44it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.33it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 26/26 [00:10<00:00,  2.56it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.34it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.48it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.46it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.47it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.34it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "100%|██████████| 26/26 [00:10<00:00,  2.41it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.45it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.31it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.40it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      " 38%|███▊      | 10/26 [00:03<00:04,  3.24it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_EPOCHS = 200\n",
    "optimizer_G = torch.optim.Adam(generator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator_model.parameters(), lr = 1e-4, betas=(0.5, 0.999))\n",
    "#x = next(iter(hdf5_dataloader))\n",
    "\n",
    "disp_img = 89\n",
    "\n",
    "gl = []\n",
    "dl = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # print(\"Epoch : \", epoch)\n",
    "    for iterate, x in enumerate(tqdm(hdf5_dataloader)):\n",
    "        \n",
    "        for i in range(1):\n",
    "        #   dataloader_iter = iter(hdf5_dataloader)\n",
    "            current_batch_size = BATCH_SIZE\n",
    "            #real_images = x.cuda()\n",
    "            #     print(real_images.shape)\n",
    "            batch_ones = torch.ones((current_batch_size, 1)).cuda()\n",
    "            batch_zeros = torch.zeros((current_batch_size, 1)).cuda()\n",
    "            # Generator Training\n",
    "            latent_vals = torch.randn((current_batch_size, LATENT_SIZE, 1, 1)).cuda()\n",
    "            # print(latent_vals.shape)\n",
    "            generated_fakes = generator_model(latent_vals)\n",
    "            discriminator_results_for_fakes = discriminator_model(generated_fakes)\n",
    "            #generator_loss = bce_loss(discriminator_results_for_fakes, batch_ones)\n",
    "            generator_loss = -torch.mean( discriminator_results_for_fakes )\n",
    "    \n",
    "            gl.append( generator_loss.item() )\n",
    "            optimizer_G.zero_grad()\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(generated_fakes[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "                    \n",
    "            plt.savefig(\"Gen_2X/Gen_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "        \n",
    "        # Discriminator Training\n",
    "        #for i in range(2):\n",
    "          #x = next(dataloader_iter)  \n",
    "        current_batch_size = x.shape[0]\n",
    "        real_images = x.cuda()\n",
    "        \n",
    "        if iterate%disp_img==0:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(3,3)\n",
    "            for pi in range(3):\n",
    "                for pj in range(3):\n",
    "                    ax[pi][pj].axis('off')\n",
    "                    ax[pi,pj].imshow(undo_normalize(real_images[c].cpu().detach().numpy().transpose(1,2,0),127.5).astype(np.uint8))\n",
    "                    c+=1\n",
    "\n",
    "            plt.savefig(\"Real_images_{}_{}.png\".format(epoch, iterate))\n",
    "            plt.close()\n",
    "\n",
    "        discriminator_results_for_true_imgs = discriminator_model(real_images)\n",
    "        discriminator_results_for_fakes = discriminator_model(generated_fakes.detach())\n",
    "          # We detach the generated_fakes because we are only training discriminator in this \n",
    "          # phase. detach() prevents the gradients from being propagated\n",
    "          #import pdb;pdb.set_trace()\n",
    "          \n",
    "          #fake_loss = bce_loss(discriminator_results_for_fakes, batch_zeros)\n",
    "          #real_loss = bce_loss(discriminator_results_for_true_imgs, batch_ones)\n",
    "        real_loss = torch.mean( discriminator_results_for_true_imgs)\n",
    "        fake_loss = torch.mean( discriminator_results_for_fakes )\n",
    "          #total_loss = fake_loss + real_loss\n",
    "        total_loss = - (real_loss - fake_loss) \n",
    "        dl.append( total_loss.item() )\n",
    "        optimizer_D.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_D.step()\n",
    "          \n",
    "        for p in discriminator_model.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-TnnYRrya8h"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP20neKDya8l"
   },
   "outputs": [],
   "source": [
    "test_latent = torch.randn((1, LATENT_SIZE)).cuda()\n",
    "\n",
    "test_gen_image = generator_model(test_latent)\n",
    "print(test_gen_image.shape)\n",
    "\n",
    "numpy_img = test_gen_image.squeeze().cpu().detach().numpy().transpose(1,2,0)\n",
    "\n",
    "numpy_img = undo_normalize(numpy_img, 127.5)\n",
    "print(numpy_img.max())\n",
    "plt.imshow(numpy_img.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqWkh0bpya8q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy_of_Computer_Vision_Project_Gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
